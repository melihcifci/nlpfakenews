{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByURXC_r3qor"
      },
      "source": [
        "# Setting up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzqF495LosZG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Melih Cifci\n",
        "#Yunus Ulusoy\n",
        "\n",
        "#Automated Misinformation & Disinformation Detection Using Transformer Embeddings\n",
        "\n",
        "\n",
        "#References are included in the Research paper at the end\n",
        "\n",
        "#HOW TO RUN\n",
        "# 1. CONNECT TO GOOGLE DRIVE VIA GOOGLE COLAB ONCE YOU RUN (give perms for it to work)\n",
        "# 2. CREATE A FOLDER IN GOOGLE DRIVE IN THE 'MY DRIVE' PATHWAY,(THE MAIN PATHWAY OF DRIVE)\n",
        "# 3. NAME THE FOLDER, 'fake-real-data'\n",
        "# 4. DOWNLOAD THE ISOT (FAKE NEWS) ZIP FILE FROM GIVEN REFERENCE AT THE BOTTOM, FROM UNIV OF VICTORIA OR ANY PUBLIC OPEN SOURCE AVAILABLE\n",
        "# 5. UNZIP IT AND DRAG BOTH FILES INTO THE GOOGLE DRIVE FOLDER, AND NAME THEM 'Fake.csv' and 'True.csv'\n",
        "# ----- Make sure to be careful of case-sensitive + necessity of using '-' in the folder,\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/fake-real-data')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import nltk\n",
        "import random\n",
        "import re\n",
        "import xgboost as xgb\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold,\n",
        "    cross_val_score\n",
        ")\n",
        "from sklearn.metrics import ( #used for data analysis\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "O0lbcWMzXxs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define seeds\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    torch.cuda.manual_seed(seed_value) # gpu vars\n",
        "    torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "    torch.backends.cudnn.deterministic = True # gpu vars\n",
        "    torch.backends.cudnn.benchmark = False # gpu vars\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed_value) # Pythonhashseed\n",
        "\n",
        "seed = 2025\n",
        "seed_all(2025)"
      ],
      "metadata": {
        "id": "LOjlMRo3XsrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iORR72UTvQq8"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "fake_path = 'Fake.csv'\n",
        "real_path = 'True.csv'\n",
        "\n",
        "\n",
        "def loading_data(fake_path=fake_path, real_path=real_path):\n",
        "\n",
        "    fake_df = pd.read_csv(fake_path).head(1174)\n",
        "    # 5% of Fake all fake, we first found out using .count of how many fakes there are multiplied by *0.05, and manually picked first 1174,\n",
        "    # better practice to randomize throughout the dataset for 5% in different states,\n",
        "\n",
        "    real_df = pd.read_csv(real_path)\n",
        "\n",
        "    fake_df['label'] = 1 # fake are labeled as 1\n",
        "    real_df['label'] = 0 # true are labeled as 0\n",
        "\n",
        "    data = pd.concat([fake_df, real_df], ignore_index=True)\n",
        "    return data[['title', 'text', 'label']]\n",
        "\n",
        "def basic_info(df): #good practice we did in lectures to make sure data is good to go\n",
        "    print(\"Final Merged Dataset --> Basic Info:\")\n",
        "    df.info()\n",
        "    print(f\"\\nShape (Rows * Columns): {df.shape}\")\n",
        "    print(\"\\nFirst 5 rows (real news):\")\n",
        "    print(df[df['label'] == 0][['title','text']].head(5))\n",
        "    print(\"\\nFirst 5 rows (fake news):\")\n",
        "    print(df[df['label'] == 1][['title','text']].head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAqUMYS4hlE5"
      },
      "outputs": [],
      "source": [
        "# Load data to df + check label distribution, + basic data description\n",
        "\n",
        "df = loading_data()\n",
        "df.label.value_counts()\n",
        "basic_info(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUVs6E_XvVGK"
      },
      "source": [
        "# Preprocess + Embedding Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQEVapdmcnm"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#basic preprocess func + lemma's\n",
        "def preprocessing_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+|<.*?>', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    clean = []\n",
        "    for i in tokens:\n",
        "        i = re.sub(r'(.)\\1{2,}', r'\\1\\1', i)\n",
        "        if i not in stop_words and len(i) > 2:\n",
        "            clean.append(lemmatizer.lemmatize(i))\n",
        "    return ' '.join(clean)\n",
        "\n",
        "# hugging face embedding transformer --> open source\n",
        "class EmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2', batch_size=32):\n",
        "        self.model_name = model_name\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        texts = list(X)\n",
        "        embeds = []\n",
        "        for i in range(0, len(texts), self.batch_size):\n",
        "            batch = texts[i:i+self.batch_size]\n",
        "            enc = self.tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
        "            enc = {k: v.to(self.device) for k, v in enc.items()}\n",
        "            with torch.no_grad():\n",
        "                out = self.model(**enc)\n",
        "            h = out.last_hidden_state\n",
        "            mask = enc['attention_mask'].unsqueeze(-1).expand(h.size()).float()\n",
        "            summed = (h * mask).sum(1)\n",
        "            counts = mask.sum(1)\n",
        "            embeds.append((summed / counts).cpu().numpy())\n",
        "        return np.vstack(embeds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4uix_Olhwuz"
      },
      "source": [
        "# ML models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def machine_learning_models(X_train_emb, X_test_emb, y_train, y_test, seed):\n",
        "    neg, pos = (y_train==0).sum(), (y_train==1).sum()\n",
        "    scale_pos_weight = neg/pos\n",
        "\n",
        "    models = {\n",
        "        \"Random Forest\": RandomForestClassifier(\n",
        "            n_estimators=100, class_weight='balanced', random_state=seed\n",
        "        ),\n",
        "        \"XGBoost\": xgb.XGBClassifier(\n",
        "            eval_metric='logloss', scale_pos_weight=scale_pos_weight,\n",
        "            verbosity=0, random_state=seed\n",
        "        ),\n",
        "        \"SVM\": LinearSVC(\n",
        "            class_weight='balanced', max_iter=5000, random_state=seed\n",
        "        )\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    trained = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # CV F1 macro\n",
        "        cv_f1 = cross_val_score(model, X_train_emb, y_train,\n",
        "                                cv=skf, scoring='f1_macro')\n",
        "        print(f\"\\n{name} 5‑Fold CV F1 macro: {cv_f1.mean():.4f} ± {cv_f1.std():.4f}\")\n",
        "\n",
        "        # train + predict\n",
        "        model.fit(X_train_emb, y_train)\n",
        "        preds = model.predict(X_test_emb)\n",
        "\n",
        "        # print confusion + classification report\n",
        "        print(f\"\\n{name} on test set:\")\n",
        "        print(confusion_matrix(y_test, preds))\n",
        "        print(classification_report(y_test, preds, digits=4))\n",
        "\n",
        "        # score vector\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_score = model.predict_proba(X_test_emb)[:,1]\n",
        "        else:\n",
        "            y_score = model.decision_function(X_test_emb)\n",
        "\n",
        "        # Precision recall curve\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
        "        ap = average_precision_score(y_test, y_score)\n",
        "        plt.figure()\n",
        "        plt.plot(recall, precision)\n",
        "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "        plt.title(f\"{name} Precision–Recall (AP={ap:.4f})\")\n",
        "        plt.grid(True); plt.show()\n",
        "\n",
        "        # ROC curve --> use AUC\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "        roc_auc = roc_auc_score(y_test, y_score)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
        "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
        "        plt.title(f\"{name} ROC (AUC={roc_auc:.4f})\")\n",
        "        plt.grid(True); plt.show()\n",
        "\n",
        "        trained[name] = model\n",
        "\n",
        "    return trained"
      ],
      "metadata": {
        "id": "ivLJmchKWcMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnuNkzFZvbc4"
      },
      "source": [
        "# Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline for running logistic regression only as baseline\n",
        "\n",
        "def fake_news_pipeline(seed):\n",
        "    df = loading_data()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df.text, df.label, test_size=0.2,\n",
        "        stratify=df.label, random_state=seed\n",
        "    )\n",
        "\n",
        "    X_train_clean = X_train.apply(preprocessing_text)\n",
        "    X_test_clean  = X_test.apply(preprocessing_text)\n",
        "    embedder = EmbeddingTransformer()\n",
        "    X_train_emb = embedder.transform(X_train_clean)\n",
        "    X_test_emb  = embedder.transform(X_test_clean)\n",
        "\n",
        "    # logistic regression\n",
        "    lr = LogisticRegression(\n",
        "        max_iter=1000, class_weight='balanced', random_state=seed\n",
        "    )\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    cv_f1 = cross_val_score(lr, X_train_emb, y_train,\n",
        "                            cv=skf, scoring='f1_macro')\n",
        "    print(f\"\\n LogisticRegression CV F1 macro: {cv_f1.mean():.4f} ± {cv_f1.std():.4f}\")\n",
        "\n",
        "    lr.fit(X_train_emb, y_train)\n",
        "    preds = lr.predict(X_test_emb)\n",
        "    print(\"\\n LogisticRegression on test set:\")\n",
        "    print(confusion_matrix(y_test, preds))\n",
        "    print(classification_report(y_test, preds, digits=4))\n",
        "\n",
        "    # PR + ROC\n",
        "    y_score = lr.predict_proba(X_test_emb)[:,1]\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
        "    ap = average_precision_score(y_test, y_score)\n",
        "    plt.figure(); plt.plot(recall, precision)\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"Precision–Recall (AP={ap:.4f})\"); plt.grid(True); plt.show()\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "    roc_auc = roc_auc_score(y_test, y_score)\n",
        "    plt.figure(); plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
        "    plt.title(f\"ROC (AUC={roc_auc:.4f})\"); plt.grid(True); plt.show()\n",
        "\n",
        "    return embedder, lr, X_test_emb, y_test\n"
      ],
      "metadata": {
        "id": "06I7jO2nXHyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline for running other ML models to compare with logit baseline classifier --> compared later\n",
        "# svm, xgboost, random forest\n",
        "\n",
        "def fake_news_w_embedding_pipeline(seed):\n",
        "    df = loading_data()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df.text, df.label, test_size=0.2,\n",
        "        stratify=df.label, random_state=seed\n",
        "    )\n",
        "    X_train_clean = X_train.apply(preprocessing_text)\n",
        "    X_test_clean  = X_test.apply(preprocessing_text)\n",
        "    embedder = EmbeddingTransformer()\n",
        "    X_train_emb = embedder.transform(X_train_clean)\n",
        "    X_test_emb  = embedder.transform(X_test_clean)\n",
        "\n",
        "    trained_models = machine_learning_models(\n",
        "        X_train_emb, X_test_emb, y_train, y_test, seed\n",
        "    )\n",
        "    return trained_models, X_test_emb, y_test\n"
      ],
      "metadata": {
        "id": "WxugO5KFg5F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeHuG_3-vhhc"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOGISTIC REGRESSION\n",
        "\n",
        "embedder, lr_model, X_test_emb, y_test = fake_news_pipeline(seed)"
      ],
      "metadata": {
        "id": "FO4D6eqTdDCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM, XGBOOST, RANDOM FORREST - pipeline\n",
        "trained_models, X_test_emb, y_test = fake_news_w_embedding_pipeline(seed)\n",
        "\n",
        "#Svm shows best results, random forest is not promising"
      ],
      "metadata": {
        "id": "l8bviXaih4yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#table inputting all of data to review and allows interpreting data easy\n",
        "\n",
        "trained_models[\"Logistic Regression\"] = lr_model\n",
        "\n",
        "rows = []\n",
        "for name, model in trained_models.items():\n",
        "    preds = model.predict(X_test_emb)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_score = model.predict_proba(X_test_emb)[:,1]\n",
        "    else:\n",
        "        y_score = model.decision_function(X_test_emb)\n",
        "\n",
        "    rows.append({\n",
        "        \"Model name\": name,\n",
        "        \"Precision (class 1)\": round(precision_score(y_test, preds, pos_label=1), 3),\n",
        "        \"Recall (class 1)\"   : round(recall_score   (y_test, preds, pos_label=1), 3),\n",
        "        \"F1 (class 1)\"       : round(f1_score       (y_test, preds, pos_label=1), 3),\n",
        "        \"F1 (macro)\"         : round(f1_score       (y_test, preds, average='macro'), 3),\n",
        "        \"Average precision\"  : round(average_precision_score(y_test, y_score), 3),\n",
        "        \"ROC AUC\"            : round(roc_auc_score  (y_test, y_score), 3)\n",
        "    })\n",
        "\n",
        "df_summary = pd.DataFrame(rows)\n",
        "print(\"Model performance summary covering all of the algothrims:\")\n",
        "print(\"\\n\" + df_summary.to_markdown(index=False))\n"
      ],
      "metadata": {
        "id": "FuAFL0W7g_iG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}